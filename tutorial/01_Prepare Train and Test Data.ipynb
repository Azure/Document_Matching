{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QnA Matching Tutorial (Prepare Train and Test Data)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Question answering systems of specific topics are highly demanded but are not quite available yet. The common use cases we see in this type of scenario include but are not limited to:\n",
    "* Live chat support\n",
    "* Chat bot\n",
    "* Document match - find a subcategory of financial/legal/.. documents that answers a particular question\n",
    "\n",
    "Therefore, we have provided 2 Notebooks with step-by-step descriptions of how to match the correct answer to a given question. To solve this problem, we train the classification models on a set of pre-canned question-answer pairs and classify a new question to its correct answer class.\n",
    "\n",
    "## Import Required Python Modules\n",
    "\n",
    "In this notebook, we use several open-source Python packages that need to be installed in a local machine or an Azure Notebook Server. An upgrade is requested if a previous version of a package has been installed in the past.\n",
    "\n",
    "We make use of the NLTK sentence tokenization capability which takes a long string of text and splits it into sentence units. The tokenizer requires the installation of the 'punkt' tokenizer models. After importing nltk, the nltk.download() function can be used to download specific packages such as 'punkt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the below code to install/upgrade the requested Python packages.\n",
    "# !pip install --upgrade --no-deps smart_open azure pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, sys, os, gc, requests, time, math, nltk, glob, os.path, ftplib, json, base64, datetime, warnings, gzip\n",
    "from collections import (namedtuple, Counter)\n",
    "from azure.storage import CloudStorageAccount\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMPTY = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Sample Data\n",
    "\n",
    "We use three sets of data in this series of notebooks. We collect the raw data from the Stack Overflow Database and extract all question-answer pairs related to the __\"JavaScript\"__ tag. For the question-answer pairs, we consider the following scenarios.\n",
    "\n",
    "1. Original Questions (Q): These questions have been asked and answered on the Stack Overflow.\n",
    "2. Duplications (D): There is a linkage among the questions. Some questions that have already been asked by others are linked to the previous/original questions as Duplications. In the Stack Overflow Database, this kind of linkage is determined by \"LINK_TYPE_DUPE = 3\". Each original question could have 0 to many duplications, which are considered as semantically equivalent to the original question.\n",
    "3. Answers (A): For each Original question and its Duplications, we have found more than one answers have solved that question. In our analysis, we only select the Accepted answer or the answer with the highest score that solved the Original question. Therefore, it's 1-to-1 mapping between Original questions and Answers and many-to-1 mapping between Duplications and Original questions. Each Original question and its Duplications have an unique AnswerId.\n",
    "4. Function Words: we consider a list of words that can only be used in between content words in the creation of phrases. This list of words, stored as a .txt file, is also used as Stop Words.\n",
    "\n",
    "See the below Data Diagram to illustrate the relationship among Original Questions (Q), Duplications (D) and Answers (A):\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Azure/Document_Matching/master/pic/data_diagram.png\">\n",
    "\n",
    "The data schema is:\n",
    "\n",
    "| Dataset | Column Name | Description\n",
    "| ----------|------------|--------\n",
    "| questions | Id | the unique question ID (primary key)\n",
    "|  | AnswerId | the unique answer ID per question\n",
    "|  | Text0 | the raw text data including the question's title and body\n",
    "|  | CreationDate | the timestamp of when the question has been asked\n",
    "| dupes | Id | the unique duplication ID (primary key)\n",
    "|  | AnswerId | the answer ID associated with the duplication\n",
    "|  | Text0 | the raw text data including the duplication's title and body\n",
    "|  | CreationDate | the timestamp of when the duplication has been asked\n",
    "| answers | Id | the unique answer ID (primary key)\n",
    "|  | text0 | the raw text data of the answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to load .tsv.gz file into Pandas data frame.\n",
    "def read_csv_gz(url, **kwargs):\n",
    "    return pd.read_csv(gzip.open(requests.get(url, stream=True).raw, mode='rb'), **kwargs)\n",
    "\n",
    "def read_data_frame(url, **kwargs):\n",
    "    return read_csv_gz(url, sep='\\t', encoding='utf8', **kwargs).set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# URLs to Original questions, Duplications, Answers and Function Words.\n",
    "questions_url = 'https://mezsa.blob.core.windows.net/stackoverflow/orig-q.tsv.gz'\n",
    "dupes_url = 'https://mezsa.blob.core.windows.net/stackoverflow/dup-q.tsv.gz'\n",
    "answers_url = 'https://mezsa.blob.core.windows.net/stackoverflow/ans.tsv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load datasets.\n",
    "questions = read_data_frame(questions_url, names=('Id', 'AnswerId', 'Text0', 'CreationDate'))\n",
    "dupes = read_data_frame(dupes_url, names=('Id', 'AnswerId', 'Text0', 'CreationDate'))\n",
    "answers = read_data_frame(answers_url, names=('Id', 'Text0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing\n",
    "\n",
    "### Clean up text\n",
    "\n",
    "Since the raw data is in HTML format, we need to clean up HTML tags and links. We also remove embedded code chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_code(text):\n",
    "    if not isinstance(text, str): return text\n",
    "    return re.sub('<pre><code>.*?</code></pre>', EMPTY, text)\n",
    "\n",
    "def strip_tags(text):\n",
    "    if not isinstance(text, str): return text\n",
    "    return re.sub('<[^>]+>', EMPTY, text)\n",
    "\n",
    "def strip_links(text):\n",
    "    if not isinstance(text, str): return text\n",
    "    def replace_link(match):\n",
    "        return EMPTY if re.match('[a-z]+://', match.group(1)) else match.group(1)\n",
    "    return re.sub('<a[^>]+>(.*)</a>', replace_link, text)\n",
    "\n",
    "def clean_text(text):\n",
    "    return strip_tags(strip_links(strip_code(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in (questions, dupes, answers):\n",
    "    df['Text'] = df['Text0'].apply(clean_text).str.lower()\n",
    "    df['NumChars'] = df['Text'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data selection criteria\n",
    "\n",
    "To obtain the high quality datasets for learning phrases, we set a threshold of minimum length of characters in the text field. This threshold is considered respectively for Original questions, Duplications and Answers. \n",
    "\n",
    "For each Original question, we also make sure there are at least 3 linked Duplications so that we have enough data to learn from in the later Notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a function to find the AnswerIds has at least 3 dupes.\n",
    "def find_answerId(answersC, dupesC, num_dupes):\n",
    "       \n",
    "    countHash = {}\n",
    "    for i in dupesC.AnswerId:\n",
    "        if i not in answersC.index.values:\n",
    "            continue\n",
    "        if i not in countHash.keys():\n",
    "            countHash[i] = 1\n",
    "        else:\n",
    "            countHash[i] += 1\n",
    "            \n",
    "    countHash = {k: v for k, v in countHash.items() if v >= num_dupes}\n",
    "    commonAnswerId = countHash.keys()\n",
    "    \n",
    "    return commonAnswerId\n",
    "\n",
    "# a function to extract data based on the selection criteria.\n",
    "def select_data(questions, dupes, answers):\n",
    "    # exclude the records without any text\n",
    "    questions_nz = questions.query('NumChars > 0')\n",
    "    dupes_nz = dupes.query('NumChars > 0')\n",
    "    answers_nz = answers.query('NumChars > 0')\n",
    "\n",
    "    # get the 10th percentile of text length as the minimum length of characters to consider in the text field\n",
    "    minLenQ = questions_nz.quantile(.1)['NumChars']\n",
    "    minLenD = dupes_nz.quantile(.1)['NumChars']\n",
    "    minLenA = answers_nz.quantile(.1)['NumChars']\n",
    "    \n",
    "    # eliminate records with text less than the minimum length\n",
    "    questionsC = questions.query('NumChars >' + str(int(minLenQ)))\n",
    "    dupesC = dupes.query('NumChars >' + str(minLenD))\n",
    "    answersC = answers.query('NumChars >' + str(minLenA))\n",
    "    \n",
    "    # remove the records in dupesC whose questionId has already existed in questionsC\n",
    "    duplicatedIndex = list(set(questionsC.index).intersection(set(dupesC.index)))\n",
    "    dupesC.drop(duplicatedIndex, inplace=True)\n",
    "    \n",
    "    # make sure Questions 1:1 match with Answers \n",
    "    matches = questionsC.merge(answersC, left_on = 'AnswerId', right_index = True)\n",
    "    questionsC = matches[['AnswerId', 'Text0_x', 'CreationDate', 'Text_x', 'NumChars_x']]\n",
    "    questionsC.columns = ['AnswerId', 'Text0', 'CreationDate', 'Text', 'NumChars']\n",
    "\n",
    "    answersC = matches[['Text0_y', 'Text_y', 'NumChars_y']]\n",
    "    answersC.index = matches['AnswerId']\n",
    "    answersC.columns = ['Text0', 'Text', 'NumChars']\n",
    "    \n",
    "    # find the AnswerIds has at least 3 dupes\n",
    "    commonAnswerId = find_answerId(answersC, dupesC, 3)\n",
    "    \n",
    "    # select the records with those AnswerIds\n",
    "    questionsC = questionsC.loc[questionsC.AnswerId.isin(commonAnswerId)]\n",
    "    dupesC = dupesC.loc[dupesC.AnswerId.isin(commonAnswerId)]\n",
    "    answersC = answersC.loc[commonAnswerId] \n",
    "    \n",
    "    return questionsC, dupesC, answersC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some questions have been linked to multiple answerIds.\n",
    "# therefore, remove the duplicated answerId for those questions.\n",
    "questions = questions.groupby(questions.index).first()\n",
    "dupes = dupes.groupby(dupes.index).first()\n",
    "questionsC, dupesC, answersC = select_data(questions, dupes, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training and Test datasets\n",
    "\n",
    "We split questions based on the creation date so that the training and the test sets are defined as below.\n",
    "1. training set = Original questions + 75% of oldest Duplications per Original question\n",
    "2. test set = remaining 25% of Duplications per Original question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a function to split Original questions and their Duplications into training and test sets.\n",
    "def split_data(questions, dupes, frac):\n",
    "    trainQ = questions\n",
    "    testQ = pd.DataFrame(columns = dupes.columns.values) # create an empty data frame\n",
    "    for answerId in np.unique(dupes.AnswerId):\n",
    "        df = dupes.query('AnswerId == ' + str(answerId))\n",
    "        totalCount = len(df)\n",
    "        splitPoint = int(totalCount * frac)\n",
    "        dfSort = df.sort_values(by = ['CreationDate'])\n",
    "        trainQ = trainQ.append(dfSort.head(splitPoint)) # oldest N percent of duplications\n",
    "        testQ = testQ.append(dfSort.tail(totalCount - splitPoint))\n",
    "    \n",
    "    # convert data type to int\n",
    "    testQ[[\"AnswerId\", \"NumChars\"]] = testQ[[\"AnswerId\", \"NumChars\"]].astype(int) \n",
    "    # rename the index \n",
    "    testQ.index.rename(\"Id\", inplace=True)\n",
    "    \n",
    "    return trainQ, testQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare training and test\n",
    "trainQ, testQ = split_data(questionsC, dupesC, 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Subsets with Sufficient Training Questions per Answer Class\n",
    "\n",
    "In our past experiment, we have noticed that some Answer class only contains a small number of training example. Training a classifier on a small amount of examples is not sufficient. Therefore, we have performed an analysis to study how the size of training example per class actually impact on the model performance.\n",
    "\n",
    "In this study, we test the __Average Rank__ and __Top 10 Percentage__ (two evaluation measures) distribution with different numbers of training examples per class. As we can see from the distribution below, our ensemble model can secure an __Average Rank__ less than 20 (out of 1201 different answer classes) and a __Top 10 Percentage__ over 70% when we have more than 15 training examples per class.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Azure/Document_Matching/master/pic/training_size.PNG\">\n",
    "\n",
    "Even the number of classes that have more than 15 training examples are very limited in our particular example, but this study is very meaningful for future works as we have learned the training example size is very critical and having a decent number of training examples per class is a must have.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Azure/Document_Matching/master/pic/training_size_details.PNG\">\n",
    "\n",
    "With the above study, we have decided to only consider the answer classes that have more than 13 training examples in this tutorial that reduces the entire dataset to 5,153 training examples, 1,735 test examples, and 103 unique answer classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countPerAns = pd.DataFrame({\"NumTrain\" : trainQ.groupby(\"AnswerId\").size()})\n",
    "trainQwithCount = trainQ.merge(countPerAns, left_on=\"AnswerId\", right_index=True)\n",
    "testQwithCount = testQ.merge(countPerAns, left_on=\"AnswerId\", right_index=True)\n",
    "answersCwithCount = answersC.merge(countPerAns, left_index=True, right_index=True)\n",
    "\n",
    "# for each Answer class, we request more than 13 training examples.\n",
    "trainQ_sub = trainQwithCount[trainQwithCount[\"NumTrain\"] > 13]\n",
    "testQ_sub = testQwithCount[testQwithCount[\"NumTrain\"] > 13]\n",
    "answersC_sub = answersCwithCount[answersCwithCount[\"NumTrain\"] > 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnswerId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>3777</td>\n",
       "      <td>call asp.net function from javascript?. i'm wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>6700</td>\n",
       "      <td>length of a javascript object (that is, associ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>7523</td>\n",
       "      <td>autosizing textarea using prototype. i'm curre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18082</th>\n",
       "      <td>1830844</td>\n",
       "      <td>validate decimal numbers in javascript - isnum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21294</th>\n",
       "      <td>242607</td>\n",
       "      <td>dynamically load a javascript file. how can yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AnswerId                                               Text\n",
       "Id                                                                \n",
       "3713       3777  call asp.net function from javascript?. i'm wr...\n",
       "5223       6700  length of a javascript object (that is, associ...\n",
       "7477       7523  autosizing textarea using prototype. i'm curre...\n",
       "18082   1830844  validate decimal numbers in javascript - isnum...\n",
       "21294    242607  dynamically load a javascript file. how can yo..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainQ[[\"AnswerId\", \"Text\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned data as .tsv and upload to Azure Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure Blob Storage\n",
    "storage_account_name = 'mezsa'\n",
    "storage_account_key = 'X1Xwyn5ROxyQa4tmvjSza/Lv5bXLu7cZ1jWyfFhCEBCKFr78onDgFUH05F5iG2aq1IsU+DIooYDbPzKa821FSA=='\n",
    "account = CloudStorageAccount(account_name=storage_account_name, account_key=storage_account_key)\n",
    "blob_service = account.create_blob_service()\n",
    "\n",
    "def save_upload_data(data, file_path, container_name, blob_name):\n",
    "    data.to_csv(file_path, sep='\\t', header=True, index=True, index_label='Id')\n",
    "    blob_service.put_block_blob_from_path(container_name=container_name, blob_name=blob_name, file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify the path in below script to upload the datasets to your own Blob Storage.\n",
    "if False: \n",
    "    save_upload_data(trainQ_sub, os.path.join(os.getcwd(), \"trainQ_tutorial.tsv\"), 'stackoverflownew', 'trainQ_tutorial.tsv')\n",
    "    save_upload_data(testQ_sub, os.path.join(os.getcwd(), \"testQ_tutorial.tsv\"), 'stackoverflownew', 'testQ_tutorial.tsv')\n",
    "    save_upload_data(answersC_sub, os.path.join(os.getcwd(), \"answersC_tutorial.tsv\"), 'stackoverflownew', 'answersC_tutorial.tsv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
